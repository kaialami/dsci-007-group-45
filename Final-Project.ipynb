{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0da7eb0b",
   "metadata": {},
   "source": [
    "# **Heart Disease Diagnostic Tool**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3755523",
   "metadata": {},
   "source": [
    "## **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175722ff",
   "metadata": {},
   "source": [
    "Cardiovascular diseases are the leading cause of death globally, estimated to take around 17.9 million lives each year. It is a group of disorders of the heart and blood vessels and include coronary heart disease, cerebrovascular disease, rheumatic heart disease and other conditions (WHO, n.d.). For our project, the question we are trying to answer is:\n",
    "\n",
    "“Can we use patient attributes from a clinic's database to predict whether a patient has heart disease?”\n",
    "\n",
    "The data set used to answer this questions was built using 303 patient information from Cleveland and was processed to include 14 out of 76 attributes most commonly used by published experiments. It was obtained from https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data (UCI Machine Learning Repository, n.d.).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f9822d",
   "metadata": {},
   "source": [
    "## **Preliminary exploratory data analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f95e28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(rvest)\n",
    "library(tidyverse)\n",
    "library(repr)\n",
    "library(tidymodels)\n",
    "options(repr.matrix.max.rows = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e13159f",
   "metadata": {},
   "source": [
    "#### **Reading and Wrangling the Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f937a4b",
   "metadata": {},
   "source": [
    "We set the seed for reproducibility and read the data from the web into an R dataframe.   \n",
    "\n",
    "The data has no column names, but using the information from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Heart+Disease) we give the dataframe its appropriate column names. We also convert the variables into numeric and categorical based on the above documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1c0a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(293)\n",
    "\n",
    "dataset_test <- download.file(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\", \n",
    "    \"heart_disease.csv\")\n",
    "\n",
    "heart_data <- read_csv(\"heart_disease.csv\", col_names = FALSE)\n",
    "\n",
    "\n",
    "heart_data <- rename(heart_data, \n",
    "                     age =X1, #represented in years - numerical\n",
    "                     sex =X2, #1 representing male; 0 representing female - categorical\n",
    "                     cp =X3, #Chest pain type - categorical \n",
    "                     trestbps =X4, #resting blood pressure (mmHg) - numerical\n",
    "                     chol = X5, #serum cholesterol (mg/dl) - numerical\n",
    "                     fbs =X6, #fasting blood sugar > 120 mg/dl (1 = true; 0 = false) - categorical\n",
    "                     restecg=X7, #resulting electrocardiographic results - categorical\n",
    "                     thalach=X8, #maximum heart rate achieved - numerical\n",
    "                     exang=X9, #exercise induced angina - categorical\n",
    "                     oldpeak=X10, #slope of peak exercise ST segment - categorical\n",
    "                     slope=X11, #slope of peak exercise ST segment - categorical\n",
    "                     ca=X12, #number of major vessels - categorical\n",
    "                     thal=X13, #thalassemia Severity - categorical\n",
    "                     diagnosis=X14) #diagnosis of heart disease - categorical\n",
    "\n",
    "idx <- heart_data == \"?\"\n",
    "is.na(heart_data) <- idx                                 #eliminates ? and replaces with NA\n",
    "\n",
    "heart_data[] <- sapply(heart_data, as.numeric) #converts all the data to numeric\n",
    "\n",
    "names = c('sex', 'cp', 'exang', 'slope', 'thal', 'diagnosis', \"restecg\", \"ca\", \"fbs\")\n",
    "heart_data[,names] <- lapply(heart_data[,names] , factor)\n",
    "\n",
    "heart_data <- mutate(heart_data, diagnosis = ifelse(diagnosis == \"1\"|diagnosis == \"2\"|diagnosis == \"3\"|diagnosis == \"4\", \"Positive\", \"Negative\"))\n",
    "heart_data <- mutate(heart_data, diagnosis = as.factor(diagnosis))          #changes the diagnosis values to strings\n",
    "\n",
    "heart_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5baf37c-b441-4690-b122-5890778c3880",
   "metadata": {},
   "source": [
    "**Table 1:** Data from the Cleveland clinic, showing patient attributes and heart disease diagnoses. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2bdba4",
   "metadata": {},
   "source": [
    "## **Methods & Results**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25318f20",
   "metadata": {},
   "source": [
    "#### **Splitting data into training and testing sets**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5a1399",
   "metadata": {},
   "source": [
    "We will be using K-nearest neighbours to solve our classification question, so we must split our data into a training set and a testing set. Training set will be used for building the classifier while the testing set will be used for evaluating accuracy of the classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dffdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_split <- initial_split(heart_data, prop = 0.75, strata = diagnosis)          #splits data\n",
    "heart_train <- training(heart_split)\n",
    "heart_test <- testing(heart_split) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cc6b1e",
   "metadata": {},
   "source": [
    "Later on we will perform a 5-fold cross-validation to select the number of neighbours that gives the highest accuracy for our classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500ff382",
   "metadata": {},
   "source": [
    "#### **Number of Positive and Negative diagnoses**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2451aade",
   "metadata": {},
   "source": [
    "Next, we will create useful summarizations of our data to select suitable predictor variables.  \n",
    "\n",
    "One useful summary of the data is the number of positive and negative diagnosis in our training data. We will calculate the total number of observations in our training data to calculate the proportion of positive and negative diagnosis represented as a percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0d5cb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_count <- nrow(heart_train)\n",
    "count_train_summary <- group_by(heart_train, diagnosis) |>    #counts number of positive/negative diagnosis\n",
    "    summarize(count=n()) |>\n",
    "    mutate(percentage = count/total_count)\n",
    "\n",
    "count_train_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fd4777-7747-4e20-b8e4-e7f59bff679a",
   "metadata": {},
   "source": [
    "**Table 2:** Counts and percentages of negative and positive heart disease cases in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a1194c",
   "metadata": {},
   "source": [
    "From the training dataset we can see there's a good representation of patients with (45.8%) and without (54.2%) heart disease which is good, as later on we will know if our diagnosis tool is actually making accurate predictions instead of always predicting postive/negative. Since negative diagnosis represents the majority of the training data, the majority classifier would always predict that a new observation is negative so the estimated accuracy of the majority classifier would be 54.2%. The accuracy of the majority classifier can be later used to evaluate the accuracy of our classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55dc1fa",
   "metadata": {},
   "source": [
    "#### **Number of missing values in each column**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef0b42a",
   "metadata": {},
   "source": [
    "We decided to avoid using ***categorical*** variables as our predictors because our goal is to perform classification using K-nearest neighbors, which would work better with numerical predictors. \n",
    "\n",
    "So, we created a table that summarizes the number of missing values for all ***numerical*** variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671b1f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_data |>\n",
    "    select(age, trestbps, chol, thalach, oldpeak, diagnosis) |>\n",
    "    summarise_all(funs(sum(is.na(.))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952e3ce8-b535-40d3-9fed-21bff81b8698",
   "metadata": {},
   "source": [
    "**Table 3:** Summary of missing values of numerical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f4557c",
   "metadata": {},
   "source": [
    "All variables of interest have no missing values, so no more data processing needs to be done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86053a25",
   "metadata": {},
   "source": [
    "#### **Average of numerical columns**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd985210",
   "metadata": {},
   "source": [
    "Another useful summarization of the data is the average value of each variable, across both positive and negative diagnoses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278c121f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_avg <- heart_train |>\n",
    "    select(age, trestbps, chol, thalach, oldpeak, diagnosis) |>\n",
    "    group_by(diagnosis) |>\n",
    "    summarize(across(age:oldpeak, mean, na.rm = TRUE))\n",
    "\n",
    "stats_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ef42c9-8ba1-4b8d-9f10-a7f80911103f",
   "metadata": {},
   "source": [
    "**Table 4:** Summary of average variables for positive and negative diagnoses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40fc9d8",
   "metadata": {},
   "source": [
    "We see that age, chol, thalach, and oldpeak have the most significant difference between positive and negative diagnoses so we will create visualizations to choose two variables out of them to use in our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0ab415",
   "metadata": {},
   "source": [
    "#### **Visualizations of Predictor Variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541f2fac",
   "metadata": {},
   "source": [
    "From the above summarizations, we were able to narrow down our list of candidate predictors. Let's go even further.\n",
    "\n",
    "We will make histogram plots of age, chol, thalach, and oldpeak to see the distribution of each of the potential predictor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baf8468",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.height = 10, repr.plot.width = 20)\n",
    "library(gridExtra)\n",
    "\n",
    "age_plot <- heart_train |>\n",
    "        ggplot(aes(x = age, fill = diagnosis)) +\n",
    "        geom_histogram() +\n",
    "        labs(x = \"Age (years)\", y = \"number of patients\", fill = \"Heart Disease Diagnosis\") + \n",
    "        ggtitle(\"(Fig. 1a) Histogram of age based on Heart Disease status\") +\n",
    "        theme(text = element_text(size = 15)) +\n",
    "        facet_grid(rows = vars(diagnosis))\n",
    "\n",
    "chol_plot <- heart_train |>\n",
    "        ggplot(aes(x = chol, fill = diagnosis)) +\n",
    "        geom_histogram() +\n",
    "        labs(x = \"Cholesterol in serum (mg/dl)\", y = \"number of patients\", fill = \"Heart Disease Diagnosis\") + \n",
    "        ggtitle(\"(Fig. 1b) Histogram of cholesterol level based on Heart Disease status\") +\n",
    "        theme(text = element_text(size = 15)) +\n",
    "        facet_grid(rows = vars(diagnosis))\n",
    "\n",
    "\n",
    "thalach_plot <- heart_train |>\n",
    "        ggplot(aes(x = thalach, fill = diagnosis)) +\n",
    "        geom_histogram() +\n",
    "        labs(x = \"Maximum Heart Rate (bpm)\", y = \"number of patients\", fill = \"Heart Disease Diagnosis\") + \n",
    "        ggtitle(\"(Fig. 1c) Histogram of max heart rate based on Heart Disease status\") +\n",
    "        theme(text = element_text(size = 15)) +\n",
    "        facet_grid(rows = vars(diagnosis))\n",
    "\n",
    "\n",
    "oldpeak_plot <- heart_train |>\n",
    "        ggplot(aes(x = oldpeak, fill = diagnosis)) +\n",
    "        geom_histogram() +\n",
    "        labs(x = \"ST depression induced by exercise relative to rest\", y = \"number of patients\", fill = \"Heart Disease Diagnosis\") + \n",
    "        ggtitle(\"(Fig. 1d) Histogram of oldpeak based on Heart Disease status\") +\n",
    "        theme(text = element_text(size = 15)) +\n",
    "        facet_grid(rows = vars(diagnosis))\n",
    "\n",
    "\n",
    "grid.arrange(age_plot, chol_plot, thalach_plot, oldpeak_plot, ncol = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e387a6e8-7035-4bd3-944b-6ee5ecc7e1a2",
   "metadata": {},
   "source": [
    "**Figure 1(a-d):** Histograms of further narrowed down numerical predictor variables, for positive and negative heart disease diagnoses (1a is age, 1b is cholesterol, 1c is max heart rate, 1d is oldpeak)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3279f77b",
   "metadata": {},
   "source": [
    "These histograms show the distribution of patients that have negative and positive diagnosis for the four variables we are exploring.\n",
    "\n",
    "The oldpeak distribution stands out the most because of the large number of zero values. All of this overlap in values gives us an inclination that oldpeak might not be suitable to use as a predictor.    \n",
    "  \n",
    "\n",
    "\n",
    "Next, we will plot each variable against every other variable in scatterplots to see if we can find any correlations in a 2D visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8167146",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.height = 5, repr.plot.width = 7)\n",
    "\n",
    "age_thalach_plot <- heart_train |>\n",
    "    ggplot(aes(x=age, y=thalach, color= diagnosis))+\n",
    "    geom_point()+\n",
    "    labs(x=\"Age\", y=\"Maximum Heart Rate (bpm)\", color=\"Heart Disease Diagnosis\") +\n",
    "    theme(text = element_text(size = 15)) +\n",
    "    ggtitle(\"(Fig. 2a) Maximum Heart Rate (Thalach) vs Age\")\n",
    "age_thalach_plot\n",
    "\n",
    "age_chol_plot <- heart_train |>\n",
    "    ggplot(aes(x=age, y=chol, color= diagnosis))+\n",
    "    geom_point()+\n",
    "    labs(x=\"Age\", y=\"Cholesterol in serum (mg/dl)\", color=\"Heart Disease Diagnosis\") +\n",
    "    theme(text = element_text(size = 15)) +\n",
    "    ggtitle(\"(Fig. 2b) Cholesterol Levels vs Age\")\n",
    "age_chol_plot\n",
    "\n",
    "age_oldpeak_plot <- heart_train |>\n",
    "    ggplot(aes(x=age, y=oldpeak, color= diagnosis))+\n",
    "    geom_point()+\n",
    "    labs(x=\"Age\", y=\"Oldpeak\", color=\"Heart Disease Diagnosis\") +\n",
    "    theme(text = element_text(size = 15)) +\n",
    "    ggtitle(\"(Fig. 2c) Oldpeak vs Age\")\n",
    "age_oldpeak_plot\n",
    "\n",
    "chol_thalach_plot <- heart_train |>\n",
    "    ggplot(aes(x=chol, y=thalach, color= diagnosis))+\n",
    "    geom_point()+\n",
    "    labs(x=\"Cholesterol in serum (mg/dl)\", y=\"Maximum Heart Rate (bpm)\", color=\"Heart Disease Diagnosis\") +\n",
    "    theme(text = element_text(size = 15)) +\n",
    "    ggtitle(\"(Fig. 2d) Maximum Heart Rate (Thalach) vs Cholesterol Levels\")\n",
    "chol_thalach_plot\n",
    "\n",
    "chol_oldpeak_plot <- heart_train |>\n",
    "    ggplot(aes(x=chol, y=oldpeak, color= diagnosis))+\n",
    "    geom_point()+\n",
    "    labs(x=\"Cholesterol in serum (mg/dl)\", y=\"Oldpeak\", color=\"Heart Disease Diagnosis\") +\n",
    "    theme(text = element_text(size = 15)) +\n",
    "    ggtitle(\"(Fig. 2e) Oldpeak vs Cholesterol Levels\")\n",
    "chol_oldpeak_plot\n",
    "\n",
    "oldpeak_thalach_plot <- heart_train |>\n",
    "    ggplot(aes(x=thalach, y=oldpeak, color= diagnosis))+\n",
    "    geom_point()+\n",
    "    labs(x=\"Maximum Heart Rate (bpm)\", y=\"Oldpeak\", color=\"Heart Disease Diagnosis\") +\n",
    "    theme(text = element_text(size = 15)) +\n",
    "    ggtitle(\"(Fig. 2f) Oldpeak vs Maximum Heart Rate (Thalach)\")\n",
    "oldpeak_thalach_plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ca0b35-b49a-4b06-8215-2880fd37aed1",
   "metadata": {},
   "source": [
    "**Figure 2(a-f):** Scatterplots of maximum heart rate vs age (2a), cholesterol vs age (2b), oldpeak vs age (2c),  max heart rate vs cholesterol (2d), oldpeak vs cholesterol (2e), and oldpeak vs max heart rate (2f)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d04659d",
   "metadata": {},
   "source": [
    "From graphs (2c), (2e), and (2f), we see that many observations had an oldpeak of zero, causing lots of overlap. It's pretty clear that the k-nn algorithm would not be happy with oldpeak as a predictor. This confirms our suspicion that we shouldn't be using the `oldpeak` variable.\n",
    "\n",
    "Looking at the remaining three graphs (2a), (2b), and (2d) plotting age, serum cholesterol and thalach against each other, we decided that `age` and `thalach` are the best variables to use in our model because the graph for thalach versus age (2a) shows more distinct regions of positive and negative heart disease diagnoses which is useful for K-nearest neighbour classification. For the other two graphs (2b) and (2d), the pattern for positive and negative heart diagnoses isn't as clear and data points for positive and negative diagnoses are more interspersed within one another. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16515055",
   "metadata": {},
   "source": [
    "### **Data Analysis**\n",
    "\n",
    "Now that we have our two predictors, `age` and `thalach`, we're one step closer to predicting the classification of a new heart disease patient. \n",
    "\n",
    "To accomplish our goal, we will first perform a 5-fold cross-validation using the `vfold_cv` function set to `v = 5`. We can create a K-nearest neighbor model specification, setting neighbors to tune, followed by a workflow analysis computing accuracies for k values from 1 to 25. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e8528c",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(293)\n",
    "\n",
    "heart_recipe <-recipe(diagnosis ~ age + thalach, data = heart_train) |>   #creates a recipe containing oldpeak+thalach\n",
    "    step_scale(all_predictors()) |>                                       #as our predictors, as well as scaling them.                         \n",
    "    step_center(all_predictors())\n",
    "\n",
    "## Cross Validation \n",
    "# using 10 folds\n",
    "heart_vfold <- vfold_cv(heart_train, v = 5, strata = diagnosis)\n",
    "\n",
    "knn_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) |>\n",
    "  set_engine(\"kknn\") |>\n",
    "  set_mode(\"classification\")\n",
    "\n",
    "k_vals <- tibble(neighbors = seq(from = 1, to = 25, by = 1))\n",
    "\n",
    "knn_results <- workflow() |>\n",
    "  add_recipe(heart_recipe) |>\n",
    "  add_model(knn_spec) |>\n",
    "    tune_grid(resamples = heart_vfold, grid = k_vals) |>\n",
    "    collect_metrics()\n",
    "\n",
    "knn_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde0c7ee-a423-4a80-895e-391cc51566fd",
   "metadata": {},
   "source": [
    "**Table 5:** K-nearest neighbours unfiltered accuracy results for different K neighbours using 5-fold cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6b739c",
   "metadata": {},
   "source": [
    "We can then filter these results for the accuracy, graph a line plot with neighbours on the x-axis and the mean on the y-axis, and extract the k value that corresponds to the highest accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d294fff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute accuracy for every fold\n",
    "accuracies <- knn_results |>\n",
    "  filter(.metric == \"accuracy\")\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bff969-e6b6-40aa-a4db-85d13bfee719",
   "metadata": {},
   "source": [
    "**Table 6:** Filtered accuracy for K-nearest neighbours using 5-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70cf8cf-f800-4e84-87aa-f67db9f59941",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get row (and K value) that corresponds to the highest accuracy\n",
    "best_k <- accuracies |>\n",
    "    filter(mean == max(mean)) |>                \n",
    "    select(neighbors) |>\n",
    "    pull()\n",
    "best_k\n",
    "\n",
    "\n",
    "#plot of Accuracy vs K\n",
    "accuracy_plot <- accuracies |>\n",
    "    ggplot(aes(x = neighbors, y = mean))+\n",
    "    geom_point()+\n",
    "    geom_line() +\n",
    "    labs(x = \"Number of Neighbours (K)\", y = \"Accuracy Estimate (mean)\") + \n",
    "    ggtitle(\"(Fig. 3) Number of Neighbours and Accuracy Estimate\") +\n",
    "    theme(text = element_text(size = 15))\n",
    "accuracy_plot\n",
    "\n",
    "print(filter(accuracies, neighbors == best_k))               #prints the accuracy of a model with best k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef289dd5-bc61-4e55-895e-ed2b51c1f528",
   "metadata": {},
   "source": [
    "**Figure 3:** Plot of accuracy estimate versus many number of neighbours values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8581efc4",
   "metadata": {},
   "source": [
    "We can see from the graph that the highest accuracy from our cross-validation tests corresponds to a k value of 19 neighbours, with an accuracy of ~71.6%. Therefore we will now create a K-nearest neighbour model using the number of neighbours set to 19."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0329a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "## KNN model creation using our optimal K value calculated from above\n",
    "\n",
    "knn_spec2 <- nearest_neighbor(weight_func = \"rectangular\", neighbors = best_k) |>   \n",
    "    set_engine(\"kknn\") |>\n",
    "    set_mode(\"classification\")\n",
    "\n",
    "heart_fit <- workflow() |>\n",
    "    add_recipe(heart_recipe) |>\n",
    "    add_model(knn_spec2) |>\n",
    "    fit(data = heart_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93db669e",
   "metadata": {},
   "source": [
    "Now, let's test this model against our test data to evaluate the performance of our model. We can also make a heat map that visualizes our k-nn algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93f0ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## test our model with the test data\n",
    "heart_test_predictions <- predict(heart_fit, heart_test) |>\n",
    "    bind_cols(heart_test)\n",
    "\n",
    "# heart_test_predictions\n",
    "\n",
    "## evaluate accuracy of our model using test data\n",
    "heart_prediction_accuracy <- heart_test_predictions |>\n",
    "    metrics(truth = diagnosis, estimate = .pred_class) |>\n",
    "    filter(.metric == \"accuracy\")\n",
    "\n",
    "heart_prediction_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db50d11f-fe19-4b8f-8dfc-85b1c8d2d623",
   "metadata": {},
   "source": [
    "**Table 7:** Accuracy of the KNN classifcation model on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f131bd-8cc5-4908-8a8f-a0e9a0308bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_mat <- heart_test_predictions |>\n",
    "    conf_mat(truth = diagnosis, estimate = .pred_class)\n",
    "heart_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a6dfb7-702b-4ae8-839d-0a0b7cfe0127",
   "metadata": {},
   "source": [
    "**Table 8**: Confusion matrix comparing true heart disease diagnoses to predicted diagnoses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920ab5b3-e571-4f5c-81c1-d794d15026ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "are_grid <- seq(min(heart_data$age), \n",
    "                max(heart_data$age), \n",
    "                length.out = 100)\n",
    "smo_grid <- seq(min(heart_data$thalach), \n",
    "                max(heart_data$thalach), \n",
    "                length.out = 100)\n",
    "asgrid <- as_tibble(expand.grid(age = are_grid, \n",
    "                                thalach = smo_grid))\n",
    "\n",
    "# use the fit workflow to make predictions at the grid points\n",
    "knnPredGrid <- predict(heart_fit, asgrid)\n",
    "\n",
    "# bind the predictions as a new column with the grid points\n",
    "prediction_table <- bind_cols(knnPredGrid, asgrid) |> \n",
    "  rename(diagnosis = .pred_class)\n",
    "\n",
    "\n",
    "## Creates a heat map of regions depicting a visual representation of how our classifier algorothim picks diagnosis.\n",
    "wkflw_plot <- heart_train |>\n",
    "  ggplot() +\n",
    "  geom_point(mapping = aes(x = age, \n",
    "                           y = thalach, \n",
    "                           color = diagnosis), \n",
    "             alpha = 0.75) +\n",
    "  geom_point(data = prediction_table, \n",
    "             mapping = aes(x = age, \n",
    "                           y = thalach, \n",
    "                           color = diagnosis), \n",
    "             alpha = 0.02, \n",
    "             size = 5) +\n",
    "  labs(color = \"Diagnosis\", \n",
    "       x = \"Age\", \n",
    "       y = \"Thalach\") +\n",
    "  scale_color_manual(labels = c(\"Positive\", \"Negative\"), \n",
    "                     values = c(\"orange2\", \"steelblue2\")) +\n",
    "  theme(text = element_text(size = 15)) +\n",
    "    ggtitle(\"(Fig. 4) Training Data with Background Colour\\nDepicting Classifier Decision\")\n",
    "\n",
    "wkflw_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f0d68b-4056-406e-9f8b-dedca83e1690",
   "metadata": {},
   "source": [
    "**Figure 4:** Heat map visualization of knn classification using age and thalach (maximum heart rate) as predictors.  Yellow is where positive diagnoses are predicted and blue is negative diagnoses are predicted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544f316b",
   "metadata": {},
   "source": [
    "## **Discussion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9081604f",
   "metadata": {},
   "source": [
    "We found that our classifier has a maximum of 71.6% accuracy after performing a 10-fold cross-validation and choosing the number of neighbours to be 19. When testing our classifier against our testing dataset, we got a 67.1% accuracy. Looking at the confusion matrix, we have 25 diagnoses that were negative which we predicted accurately and 26 diagnoses that were positive which we predicted accurately. However, 9 positive diagnoses were predicted to be negative and 16 negative diagnoses were predicted to be positive. Since predicting a negative diagnosis to be positive is less severe than predicting a positive diagnosis to be negative, we have 9 out of 76 cases (11.8%) that would result in severe consequences. We also created a scatter plot of thalach versus age where the background colour indicates the decision of the classifier.\n",
    "\n",
    "We intially set out to determine if we could create a classificiation algorithim based on K-nearest neighbours using attributes from the cleveland heart disease data set. Our expectation was to create a classifier that had at least 90% accuracy so that we can potentially use it for predicting heart disease. However, after visualizing the data, we determined that the best attributes to use as predictors were `age` and `thalach`. The K-nearest neighbour classification model we made resulted in a 67.1% accuracy against new data, which is significantly lower than what we had hoped for. With that being said, our classifier is still slightly better than making random diagnosis aligning with our expectations based off the histogram and scatter plot analysis. Also, the accuracy of our classifier is around 13% higher than the majority classifier calculated in the \"Methods and Results\" section which has an accuracy of 54.2% so our method is extracting some useful information from our predictor variables. However, due to the importance of making an accurate diagnosis this low accuracy level is not suitable for our purposes in predicting heart disease. The low accuracy of our classifier might be improved by using a larger dataset so that we have more training data to train our classifier resulting in improved accuracy.\n",
    "\n",
    "Our findings show that using the two attributes, `thalach` (max heart rate) and `age`, alone is unlikely sufficient enough to produce an accurate K-nearest neighbour model. However, since our results show a strong correlation between maximum heart rate and age with increased risk of heart disease. Perhaps under a different prediction model and/or with more prediction factors, maximum heart rate and age can still be used as important attributes to look out for when assessing heart disease risk. Or doctors could look at maximum heart rate and age as stronger indicators/risk factors when assessing heart disease risk in patients. \n",
    "\n",
    "The mortality rate of heart diseases can be reduced if the diseases can be accurately predicted at early stages and preventative measures are implemented right away (Devi et al., 2021). A future question our project leads to is if a different selection of attributes or a different prediction model be used to predict heart disease in patients. Since our project was based soley off the Cleveland dataset, future projects from datasets like the ones from Hungary and Switzerland can be used to test if other attributes are better indicators of heart disease or if the attributes we used (`thalach` and `age`) are less accurate in the different datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135d86ef",
   "metadata": {},
   "source": [
    "## **References**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b18492d",
   "metadata": {},
   "source": [
    "Devi, A. G., Borra, S. P. R., & Sagar, K. V. (2021). A Method of Cardiovascular Disease Prediction using Machine Learning. IJERT. Retrieved Arpil 9, 2023, from https://doi.org/10.17577/IJERTCONV9IS05050\n",
    "\n",
    "Heart Disease Data Set. (n.d.). UCI Machine Learning Repository. Retrieved March 11, 2023 from https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "\n",
    "World Health Organization. (n.d.). Cardiovascular diseases. World Health Organization. Retrieved March 11, 2023, from https://www.who.int/health-topics/cardiovascular-diseases#tab=tab_1 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
